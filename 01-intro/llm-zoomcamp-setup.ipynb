{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95500968-6b31-42f9-8892-852dab052940",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"is it too late to join the course?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a098c-34c5-473a-8f28-5796f6869e27",
   "metadata": {},
   "source": [
    "# OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c6a7572-101d-4e43-a671-b65f5849e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a766af81-7246-4bd2-86f9-4dabba5442e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39d7743e-0144-44b2-b046-65068616c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f758c21e-f5ee-4836-ae55-9fe27f98dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c6aadb-f245-4ec7-9fc0-c4df7b51a80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would need a bit more information to give you a tailored response. However, generally speaking, whether it is too late to join a course depends on several factors, such as:\\n\\n1. **Enrollment Deadlines:** Check if the course has a specific enrollment deadline. If the deadline has passed, you might not be able to join unless exceptions are made.\\n\\n2. **Course Progress:** Consider how far along the course is. If it’s already well underway, joining late might make it difficult to catch up on missed content.\\n\\n3. **Instructor Policies:** Some instructors or institutions are flexible about late enrollments, especially if you have a good reason for your delay.\\n\\n4. **Format of the Course:** Online courses might allow more flexibility with start dates, especially if they are self-paced.\\n\\n5. **Availability of Resources:** Ensure you have access to any necessary materials or resources, regardless of when you join.\\n\\nIt’s best to contact the course administrator or instructor directly to inquire about joining the course late and to discuss any possible accommodations.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cfa11-8d55-4fc2-86d8-b0bc90b80c5c",
   "metadata": {},
   "source": [
    "## Google Generative AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5926dac3-d62f-4ef2-993c-a518c862bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4a8d0b-76d4-46cc-86b4-785da06f2782",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7eb919-0f7a-41bd-aa85-82d89f347db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models for text generation:\n",
      "- models/gemini-1.0-pro-vision-latest\n",
      "- models/gemini-pro-vision\n",
      "- models/gemini-1.5-pro-latest\n",
      "- models/gemini-1.5-pro-001\n",
      "- models/gemini-1.5-pro-002\n",
      "- models/gemini-1.5-pro\n",
      "- models/gemini-1.5-flash-latest\n",
      "- models/gemini-1.5-flash-001\n",
      "- models/gemini-1.5-flash-001-tuning\n",
      "- models/gemini-1.5-flash\n",
      "- models/gemini-1.5-flash-002\n",
      "- models/gemini-1.5-flash-8b\n",
      "- models/gemini-1.5-flash-8b-001\n",
      "- models/gemini-1.5-flash-8b-latest\n",
      "- models/gemini-1.5-flash-8b-exp-0827\n",
      "- models/gemini-1.5-flash-8b-exp-0924\n",
      "- models/gemini-2.5-pro-exp-03-25\n",
      "- models/gemini-2.5-pro-preview-03-25\n",
      "- models/gemini-2.5-flash-preview-04-17\n",
      "- models/gemini-2.5-flash-preview-05-20\n",
      "- models/gemini-2.5-flash-preview-04-17-thinking\n",
      "- models/gemini-2.5-pro-preview-05-06\n",
      "- models/gemini-2.5-pro-preview-06-05\n",
      "- models/gemini-2.0-flash-exp\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.0-flash-lite-preview-02-05\n",
      "- models/gemini-2.0-flash-lite-preview\n",
      "- models/gemini-2.0-pro-exp\n",
      "- models/gemini-2.0-pro-exp-02-05\n",
      "- models/gemini-exp-1206\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21\n",
      "- models/gemini-2.0-flash-thinking-exp\n",
      "- models/gemini-2.0-flash-thinking-exp-1219\n",
      "- models/gemini-2.5-flash-preview-tts\n",
      "- models/gemini-2.5-pro-preview-tts\n",
      "- models/learnlm-2.0-flash-experimental\n",
      "- models/gemma-3-1b-it\n",
      "- models/gemma-3-4b-it\n",
      "- models/gemma-3-12b-it\n",
      "- models/gemma-3-27b-it\n",
      "- models/gemma-3n-e4b-it\n",
      "\n",
      "Available models for embeddings:\n",
      "- models/embedding-001\n",
      "- models/text-embedding-004\n",
      "- models/gemini-embedding-exp-03-07\n",
      "- models/gemini-embedding-exp\n"
     ]
    }
   ],
   "source": [
    "print(\"Available models for text generation:\")\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(f\"- {m.name}\")\n",
    "\n",
    "print(\"\\nAvailable models for embeddings:\")\n",
    "for m in genai.list_models():\n",
    "  if 'embedContent' in m.supported_generation_methods:\n",
    "    print(f\"- {m.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9326b84d-dbcd-4592-a37e-369fd3a80274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That completely depends on the specific course!\n",
      "\n",
      "To give you an answer, I need a little more information:\n",
      "\n",
      "1.  **What course are you referring to?** (e.g., a university course, an online course from Coursera/Udemy, a local workshop, etc.)\n",
      "2.  **When did it start, or when is it scheduled to start?**\n",
      "3.  **Do you know if there was an enrollment deadline?**\n",
      "\n",
      "**Here's how you can generally find out:**\n",
      "\n",
      "*   **Check the course website or listing:** This is usually the best place to find enrollment deadlines, start dates, and late registration policies.\n",
      "*   **Contact the course provider/instructor:** If the information isn't clear online, reach out to them directly.\n",
      "*   **Look for an FAQ section:** Many courses have an FAQ that might address late enrollment.\n",
      "\n",
      "**In general:**\n",
      "\n",
      "*   **Self-paced online courses:** You can often join these anytime.\n",
      "*   **Courses with fixed start/end dates (like university semesters or cohort-based online programs):** These often have stricter deadlines. Sometimes late enrollment is possible, but you might have missed some material.\n",
      "*   **Workshops/short courses:** These often have firm cut-offs due to limited space or pre-course preparation.\n",
      "\n",
      "**If you can tell me more about the course, I might be able to give you more specific advice on where to look!**\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-2.5-pro-preview-05-06\")\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53f678-6e2b-4f81-a65d-caf732f946f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
